{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas, numpy, matplotlib and seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib as joblib\n",
    "\n",
    "# RiotWatcher\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import sys\n",
    "import dill\n",
    "import ipython_genutils\n",
    "\n",
    "# Custom scripts\n",
    "from extract_players_performance import extract_players_performance\n",
    "from remove_perks import remove_perks\n",
    "from cleaner import replace_champ_names_with_tags\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_champ_tags = ['Marksman', 'Fighter','Mage','Tank','Assassin','Support']\n",
    "\n",
    "champ_data = {}\n",
    "with open('../champion_data/champion.json','r',encoding='utf-8') as f :\n",
    "    champions = json.load(f)\n",
    "    for champion in champions['data'] :\n",
    "        champ_data[str.lower(champion)] = champions['data'][champion]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def add(old,new_df) :\n",
    "    appended_df = pd.concat([old,new_df],ignore_index=True)\n",
    "    return appended_df\n",
    "\n",
    "def champ_name_replacer(champ_name) :\n",
    "    return champ_data[str.lower(champ_name)]['tags'][0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:\n",
      "(74239, 15)\n",
      "\n",
      "dataframe sample:\n",
      "  dmg_carry_0 obj_carry_0 team_comp_0_champ_1 team_comp_0_champ_2  \\\n",
      "0    Marksman     Fighter             Fighter            Marksman   \n",
      "\n",
      "  team_comp_0_champ_3 team_comp_0_champ_4 team_comp_0_champ_5 dmg_carry_1  \\\n",
      "0            Marksman            Marksman            Marksman    Marksman   \n",
      "\n",
      "  obj_carry_1 team_comp_1_champ_1 team_comp_1_champ_2 team_comp_1_champ_3  \\\n",
      "0     Fighter                Tank             Fighter                Mage   \n",
      "\n",
      "  team_comp_1_champ_4 team_comp_1_champ_5  final_match_winner  \n",
      "0            Marksman                Mage                   1  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../ml_data/full_ml_data.csv')\n",
    "columns = list(df.columns)\n",
    "champ_name_columns = [c for c in columns if c.startswith('team_comp') or c.startswith('dmg_carry') or c.startswith('obj_carry')]\n",
    "\n",
    "\n",
    "for c in champ_name_columns :\n",
    "    df[c] = df[c].apply(lambda x : champ_name_replacer(x))\n",
    "\n",
    "# only team composition related rows\n",
    "df = df[champ_name_columns+['final_match_winner']]\n",
    "# df = df[:100]\n",
    "print(f\"dataframe shape:\\n{df.shape}\\n\")\n",
    "print(f\"dataframe sample:\\n{df.head(1)}\\n\")\n",
    "\n",
    "\n",
    "### MUST RETRIEVE ALL POSSIBLE CHAMP TAGS BEFORE BEING ABLE TO ONE HOT ENCODE. \n",
    "# ONE POSSIBLE SOLUTION IS TO ADD DUMMY DATA FOR WHICH IT WOULD HELP GENERATE THE ONE HOT ENCODE VALUE FOR EACH CHAMPION TAG FOR EACH CATEGORICAL FEATURE IN THE DATASET (6 CHAMP TAGS -> 6 EXTRA DUMMY ROWS, 1 FOR EACH CHAMP TAG)\n",
    "def fill_missing_champ_tags_with_dummy(df): \n",
    "    print(unique_champ_tags)\n",
    "    dummy_dict = {}\n",
    "    for k in champ_name_columns :\n",
    "        dummy_dict[k] = unique_champ_tags.copy()\n",
    "    print(dummy_dict)\n",
    "    dummy_df = pd.DataFrame(dummy_dict)\n",
    "    dummy_df = dummy_df.replace(np.nan,0)\n",
    "    extra_rows = dummy_df.shape[0]\n",
    "    print('Number of extra dummy rows = ',extra_rows)\n",
    "    df = add(df,dummy_df)\n",
    "    return (df,extra_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data and labels : (49740, 14) (49740,)\n",
      "Shape of test data and labels : (24499, 14) (24499,)\n"
     ]
    }
   ],
   "source": [
    "data = df.drop(\"final_match_winner\",axis=1)\n",
    "labels = df[\"final_match_winner\"].copy()\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(data,labels,test_size=0.33,random_state=42)\n",
    "\n",
    "print('Shape of training data and labels :',X_train.shape,y_train.shape)\n",
    "print('Shape of test data and labels :',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      " Empty DataFrame\n",
      "Columns: [dmg_carry_0, obj_carry_0, team_comp_0_champ_1, team_comp_0_champ_2, team_comp_0_champ_3, team_comp_0_champ_4, team_comp_0_champ_5, dmg_carry_1, obj_carry_1, team_comp_1_champ_1, team_comp_1_champ_2, team_comp_1_champ_3, team_comp_1_champ_4, team_comp_1_champ_5]\n",
      "Index: []\n",
      "Missing value row shape: (0, 14)\n"
     ]
    }
   ],
   "source": [
    "missing_value_row =  data[data.isnull().any(axis=1)].head()\n",
    "print(f'Rows with missing values:\\n {missing_value_row}')\n",
    "print(f'Missing value row shape: {missing_value_row.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (49746, 14)\n",
      "Columns of training data : Index(['dmg_carry_0', 'obj_carry_0', 'team_comp_0_champ_1',\n",
      "       'team_comp_0_champ_2', 'team_comp_0_champ_3', 'team_comp_0_champ_4',\n",
      "       'team_comp_0_champ_5', 'dmg_carry_1', 'obj_carry_1',\n",
      "       'team_comp_1_champ_1', 'team_comp_1_champ_2', 'team_comp_1_champ_3',\n",
      "       'team_comp_1_champ_4', 'team_comp_1_champ_5'],\n",
      "      dtype='object')\n",
      "One hot encoded Training data shape (without dummy) : (49740, 84)\n"
     ]
    }
   ],
   "source": [
    "X_train,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_train)\n",
    "print('Training data shape (with dummy) :',X_train.shape)\n",
    "print('Columns of training data :',X_train.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_train.columns)),set(champ_name_columns)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "size = X_train_prepared.shape[0]\n",
    "X_train_prepared = X_train_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Training data shape (without dummy) :',X_train_prepared.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dmg_carry_0', 'obj_carry_0', 'team_comp_0_champ_1',\n",
      "       'team_comp_0_champ_2', 'team_comp_0_champ_3', 'team_comp_0_champ_4',\n",
      "       'team_comp_0_champ_5', 'dmg_carry_1', 'obj_carry_1',\n",
      "       'team_comp_1_champ_1', 'team_comp_1_champ_2', 'team_comp_1_champ_3',\n",
      "       'team_comp_1_champ_4', 'team_comp_1_champ_5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data\n",
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "\n",
    "# Decision Trees\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forests\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "SVM Grid Search Completed.\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "DT Grid Search Completed.\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "RF Grid Search Completed.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "NB Grid Search Completed.\n",
      "SVC best params:\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Decision Tree best params:\n",
      "{'max_depth': 4, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "Random Forest best params:\n",
      "{'bootstrap': False, 'max_depth': 5, 'n_estimators': 100}\n",
      "Naive Bayes best params:\n",
      "{}\n",
      "SVC best estimator:\n",
      "SVC(C=100, gamma=0.001)\n",
      "Decision Tree best estimator:\n",
      "DecisionTreeClassifier(max_depth=4, min_samples_leaf=10, min_samples_split=5)\n",
      "Random Forest best estimator:\n",
      "RandomForestClassifier(bootstrap=False, max_depth=5)\n",
      "Naive Bayes best estimator:\n",
      "GaussianNB()\n",
      "SVC best score:\n",
      "0.6972925887103035\n",
      "Decision Tree best score:\n",
      "0.6573422334808603\n",
      "Random Forest best score:\n",
      "0.6910002717602298\n",
      "Naive Bayes best score:\n",
      "0.6368344786085876\n"
     ]
    }
   ],
   "source": [
    "# use sklearn GridSearchCV to train selected model with hyperparameter tuning\n",
    "# parameters for SVC:\n",
    "    # C -> e.g., 10, 100\n",
    "    # gamma ->  e.g., 0.001, 0.0001\n",
    "    # kernel -> 'rbf' or 'linear' \n",
    "\n",
    "svm_params = [\n",
    "    {'C':[10,100],'gamma':[0.001,0.0001],'kernel':['rbf','linear']}\n",
    "]\n",
    "\n",
    "# parameters for DecisionTreeClassifier: \n",
    "    # max_depth ->  e.g., 3, 4\n",
    "    # min_samples_split -> 5, 10\n",
    "    # min_samples_leaf -> 10, 20\n",
    "dt_params = [\n",
    "    {'max_depth':[3,4],'min_samples_split':[5,10],'min_samples_leaf':[10,20]}\n",
    "]\n",
    "\n",
    "# parameters for RandomForestClassifier: \n",
    "    # n_estimators -> 100, 200\n",
    "    # max_depth -> 3, 5\n",
    "    # bootstrap -> True, False\n",
    "rf_params = [\n",
    "    {'n_estimators':[100,200],'max_depth':[3,5],'bootstrap':[True,False]}\n",
    "]\n",
    "\n",
    "nb_params = [{}]\n",
    "# initialize gridsearch with the required parameters, including the following scoring methods and refit='bal_accuracy' (2)\n",
    "scoring = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "grid_search_svc = GridSearchCV(svm_model,svm_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True,verbose=1)\n",
    "grid_search_dt = GridSearchCV(dt_model,dt_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True,verbose=1)\n",
    "grid_search_rf = GridSearchCV(rf_model,rf_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True,verbose=1)\n",
    "grid_search_nb = GridSearchCV(nb_model,nb_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True,verbose=1)\n",
    "\n",
    "# fit the training data (0.5)\n",
    "grid_search_svc.fit(X_train_prepared,y_train)\n",
    "print(\"SVM Grid Search Completed.\")\n",
    "grid_search_dt.fit(X_train_prepared,y_train)\n",
    "print(\"DT Grid Search Completed.\")\n",
    "grid_search_rf.fit(X_train_prepared,y_train)\n",
    "print(\"RF Grid Search Completed.\")\n",
    "grid_search_nb.fit(X_train_prepared.toarray(),y_train)\n",
    "print(\"NB Grid Search Completed.\")\n",
    "\n",
    "# print the best parameters (0.5)\n",
    "print(f'SVC best params:\\n{grid_search_svc.best_params_}')\n",
    "print(f'Decision Tree best params:\\n{grid_search_dt.best_params_}')\n",
    "print(f'Random Forest best params:\\n{grid_search_rf.best_params_}')\n",
    "print(f'Naive Bayes best params:\\n{grid_search_nb.best_params_}')\n",
    "\n",
    "# print the best estimator (0.5)\n",
    "print(f'SVC best estimator:\\n{grid_search_svc.best_estimator_}')\n",
    "print(f'Decision Tree best estimator:\\n{grid_search_dt.best_estimator_}')\n",
    "print(f'Random Forest best estimator:\\n{grid_search_rf.best_estimator_}')\n",
    "print(f'Naive Bayes best estimator:\\n{grid_search_nb.best_estimator_}')\n",
    "\n",
    "# print the best score from trained GridSearchCV model (0.5)\n",
    "print(f'SVC best score:\\n{grid_search_svc.best_score_}')\n",
    "print(f'Decision Tree best score:\\n{grid_search_dt.best_score_}')\n",
    "print(f'Random Forest best score:\\n{grid_search_rf.best_score_}')\n",
    "print(f'Naive Bayes best score:\\n{grid_search_nb.best_score_}')\n",
    "\n",
    "# Save session to \"notebook_env.db\"\n",
    "dill.dump_session(\"teamcomp_notebook_env.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (24505, 14)\n",
      "Columns of training data : Index(['dmg_carry_0', 'obj_carry_0', 'team_comp_0_champ_1',\n",
      "       'team_comp_0_champ_2', 'team_comp_0_champ_3', 'team_comp_0_champ_4',\n",
      "       'team_comp_0_champ_5', 'dmg_carry_1', 'obj_carry_1',\n",
      "       'team_comp_1_champ_1', 'team_comp_1_champ_2', 'team_comp_1_champ_3',\n",
      "       'team_comp_1_champ_4', 'team_comp_1_champ_5'],\n",
      "      dtype='object')\n",
      "One hot encoded Testing data shape (without dummy) : (24499, 84)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X_test dataset based on previous method for X_train\n",
    "X_test,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_test)\n",
    "print('Training data shape (with dummy) :',X_test.shape)\n",
    "print('Columns of training data :',X_test.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_test.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
    "size = X_test_prepared.shape[0]\n",
    "X_test_prepared = X_test_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Testing data shape (without dummy) :',X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models with test data\n",
    "\n",
    "# Using the following existing variables:\n",
    "# X_test_prepared: test data\n",
    "# y_test: test labels\n",
    "# Models:\n",
    "# grid_search_svc\n",
    "# grid_search_dt\n",
    "# grid_search_rf\n",
    "# grid_search_nb\n",
    "\n",
    "# Predict using models' best estimators\n",
    "prediction_svc = grid_search_svc.best_estimator_.predict(X_test_prepared)\n",
    "prediction_dt = grid_search_dt.best_estimator_.predict(X_test_prepared)\n",
    "prediction_rf = grid_search_rf.best_estimator_.predict(X_test_prepared)\n",
    "prediction_nb = grid_search_nb.best_estimator_.predict(X_test_prepared.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: SVC:\n",
      "[[9190 3382]\n",
      " [3990 7937]]\n",
      "\n",
      "Confusion matrix: DT:\n",
      "[[10374  2198]\n",
      " [ 6132  5795]]\n",
      "\n",
      "Confusion matrix: RF:\n",
      "[[9946 2626]\n",
      " [5057 6870]]\n",
      "\n",
      "Confusion matrix: NB:\n",
      "[[7066 5506]\n",
      " [3351 8576]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and print classification reports for all models\n",
    "\n",
    "# SVC\n",
    "conf_matrix_svc = confusion_matrix(y_test, prediction_svc)\n",
    "class_report_svc = classification_report(y_test, prediction_svc, output_dict=True)\n",
    "print(f'Confusion matrix: SVC:\\n{conf_matrix_svc}\\n')\n",
    "\n",
    "# Decision Tree\n",
    "conf_matrix_dt = confusion_matrix(y_test, prediction_dt)\n",
    "class_report_dt = classification_report(y_test, prediction_dt, output_dict=True)\n",
    "print(f'Confusion matrix: DT:\\n{conf_matrix_dt}\\n')\n",
    "\n",
    "# Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, prediction_rf)\n",
    "class_report_rf = classification_report(y_test, prediction_rf, output_dict=True)\n",
    "print(f'Confusion matrix: RF:\\n{conf_matrix_rf}\\n')\n",
    "\n",
    "# Naive Bayes\n",
    "conf_matrix_nb = confusion_matrix(y_test, prediction_nb)\n",
    "class_report_nb = classification_report(y_test, prediction_nb, output_dict=True)\n",
    "print(f'Confusion matrix: NB:\\n{conf_matrix_nb}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score      support\n",
      "accuracy       0.699090  0.699090  0.699090      0.69909\n",
      "macro avg      0.699239  0.698227  0.698301  24499.00000\n",
      "weighted avg   0.699188  0.699090  0.698707  24499.00000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.659986  0.659986  0.659986      0.659986\n",
      "macro avg      0.676754  0.655520  0.647678  24499.000000\n",
      "weighted avg   0.675484  0.659986  0.649412  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.686395  0.686395  0.686395      0.686395\n",
      "macro avg      0.693198  0.683564  0.681372  24499.000000\n",
      "weighted avg   0.692402  0.686395  0.682426  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.638475  0.638475  0.638475      0.638475\n",
      "macro avg      0.643659  0.640542  0.637096  24499.000000\n",
      "weighted avg   0.644572  0.638475  0.636508  24499.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print our classification reports\n",
    "\n",
    "# SVC\n",
    "df_svc = pd.DataFrame(class_report_svc).transpose().drop(['0', '1'])\n",
    "print(f\"{df_svc}\\n\")\n",
    "\n",
    "# DT\n",
    "df_dt = pd.DataFrame(class_report_dt).transpose().drop(['0', '1'])\n",
    "print(f\"{df_dt}\\n\")\n",
    "\n",
    "# RF\n",
    "df_rf = pd.DataFrame(class_report_rf).transpose().drop(['0', '1'])\n",
    "print(f\"{df_rf}\\n\")\n",
    "\n",
    "# NB\n",
    "df_nb = pd.DataFrame(class_report_nb).transpose().drop(['0', '1'])\n",
    "print(f\"{df_nb}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session(\"teamcomp_notebook_env.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session(\"teamcomp_notebook_env.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_team_comp_rf.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_search_svc, '../models/model_team_comp_svc.pkl')\n",
    "joblib.dump(grid_search_dt, '../models/model_team_comp_dt.pkl')\n",
    "joblib.dump(grid_search_nb, '../models/model_team_comp_nb.pkl')\n",
    "joblib.dump(grid_search_rf, '../models/model_team_comp_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dmg_carry_0 obj_carry_0 team_comp_0_champ_1 team_comp_0_champ_2  \\\n",
      "0     Fighter     Fighter             Fighter             Fighter   \n",
      "\n",
      "  team_comp_0_champ_3 team_comp_0_champ_4 team_comp_0_champ_5 dmg_carry_1  \\\n",
      "0             Fighter             Fighter             Fighter     Fighter   \n",
      "\n",
      "  obj_carry_1 team_comp_1_champ_1 team_comp_1_champ_2 team_comp_1_champ_3  \\\n",
      "0     Fighter             Fighter             Fighter             Fighter   \n",
      "\n",
      "  team_comp_1_champ_4 team_comp_1_champ_5  \n",
      "0             Fighter             Fighter  \n",
      "['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support']\n",
      "{'dmg_carry_0': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'obj_carry_0': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_0_champ_1': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_0_champ_2': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_0_champ_3': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_0_champ_4': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_0_champ_5': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'dmg_carry_1': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'obj_carry_1': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_1_champ_1': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_1_champ_2': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_1_champ_3': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_1_champ_4': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support'], 'team_comp_1_champ_5': ['Marksman', 'Fighter', 'Mage', 'Tank', 'Assassin', 'Support']}\n",
      "Number of extra dummy rows =  6\n",
      "  dmg_carry_0 obj_carry_0 team_comp_0_champ_1 team_comp_0_champ_2  \\\n",
      "0     Fighter     Fighter             Fighter             Fighter   \n",
      "1    Marksman    Marksman            Marksman            Marksman   \n",
      "2     Fighter     Fighter             Fighter             Fighter   \n",
      "3        Mage        Mage                Mage                Mage   \n",
      "4        Tank        Tank                Tank                Tank   \n",
      "5    Assassin    Assassin            Assassin            Assassin   \n",
      "6     Support     Support             Support             Support   \n",
      "\n",
      "  team_comp_0_champ_3 team_comp_0_champ_4 team_comp_0_champ_5 dmg_carry_1  \\\n",
      "0             Fighter             Fighter             Fighter     Fighter   \n",
      "1            Marksman            Marksman            Marksman    Marksman   \n",
      "2             Fighter             Fighter             Fighter     Fighter   \n",
      "3                Mage                Mage                Mage        Mage   \n",
      "4                Tank                Tank                Tank        Tank   \n",
      "5            Assassin            Assassin            Assassin    Assassin   \n",
      "6             Support             Support             Support     Support   \n",
      "\n",
      "  obj_carry_1 team_comp_1_champ_1 team_comp_1_champ_2 team_comp_1_champ_3  \\\n",
      "0     Fighter             Fighter             Fighter             Fighter   \n",
      "1    Marksman            Marksman            Marksman            Marksman   \n",
      "2     Fighter             Fighter             Fighter             Fighter   \n",
      "3        Mage                Mage                Mage                Mage   \n",
      "4        Tank                Tank                Tank                Tank   \n",
      "5    Assassin            Assassin            Assassin            Assassin   \n",
      "6     Support             Support             Support             Support   \n",
      "\n",
      "  team_comp_1_champ_4 team_comp_1_champ_5  \n",
      "0             Fighter             Fighter  \n",
      "1            Marksman            Marksman  \n",
      "2             Fighter             Fighter  \n",
      "3                Mage                Mage  \n",
      "4                Tank                Tank  \n",
      "5            Assassin            Assassin  \n",
      "6             Support             Support  \n",
      "Training data shape (with dummy) : (7, 14)\n",
      "Columns of training data : Index(['dmg_carry_0', 'obj_carry_0', 'team_comp_0_champ_1',\n",
      "       'team_comp_0_champ_2', 'team_comp_0_champ_3', 'team_comp_0_champ_4',\n",
      "       'team_comp_0_champ_5', 'dmg_carry_1', 'obj_carry_1',\n",
      "       'team_comp_1_champ_1', 'team_comp_1_champ_2', 'team_comp_1_champ_3',\n",
      "       'team_comp_1_champ_4', 'team_comp_1_champ_5'],\n",
      "      dtype='object')\n",
      "One hot encoded Testing data shape (without dummy) : (1, 84)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('../models/model_team_comp_svc.pkl')\n",
    "test = {\n",
    "   \"dmg_carry_0\":[\"Aatrox\"],\n",
    "   \"obj_carry_0\":[\"Aatrox\"],\n",
    "   \"team_comp_0_champ_1\":[\"Aatrox\"],\n",
    "   \"team_comp_0_champ_2\":[\"Aatrox\"],\n",
    "   \"team_comp_0_champ_3\":[\"Aatrox\"],\n",
    "   \"team_comp_0_champ_4\":[\"Aatrox\"],\n",
    "   \"team_comp_0_champ_5\":[\"Aatrox\"],\n",
    "   \"dmg_carry_1\":[\"Aatrox\"],\n",
    "   \"obj_carry_1\":[\"Aatrox\"],\n",
    "   \"team_comp_1_champ_1\":[\"Aatrox\"],\n",
    "   \"team_comp_1_champ_2\":[\"Aatrox\"],\n",
    "   \"team_comp_1_champ_3\":[\"Aatrox\"],\n",
    "   \"team_comp_1_champ_4\":[\"Aatrox\"],\n",
    "   \"team_comp_1_champ_5\":[\"Aatrox\"]\n",
    "}\n",
    "df = pd.DataFrame(test)\n",
    "\n",
    "for c in champ_name_columns :\n",
    "    df[c] = df[c].apply(lambda x : champ_name_replacer(x))\n",
    "    \n",
    "print(df)\n",
    "X_test,dummy_rows_len = fill_missing_champ_tags_with_dummy(df)\n",
    "print(X_test)\n",
    "print('Training data shape (with dummy) :',X_test.shape)\n",
    "print('Columns of training data :',X_test.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_test.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
    "size = X_test_prepared.shape[0]\n",
    "X_test_prepared = X_test_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Testing data shape (without dummy) :',X_test_prepared.shape)\n",
    "prediction = model.predict(X_test_prepared)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e80926609d05e9d93fc8f5a4ca830eb95187a74de0c9b551d07cafde795a7924"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
