{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas, numpy, matplotlib and seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# RiotWatcher\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import sys\n",
    "import dill\n",
    "import ipython_genutils\n",
    "\n",
    "# Custom scripts\n",
    "from extract_players_performance import extract_players_performance\n",
    "from remove_perks import remove_perks\n",
    "from cleaner import replace_champ_names_with_tags\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_data = {}\n",
    "with open('../champion_data/champion.json','r',encoding='utf-8') as f :\n",
    "    champions = json.load(f)\n",
    "    for champion in champions['data'] :\n",
    "        champ_data[str.lower(champion)] = champions['data'][champion]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def add(old,new_df) :\n",
    "    appended_df = pd.concat([old,new_df],ignore_index=True)\n",
    "    return appended_df\n",
    "\n",
    "def champ_name_replacer(champ_name) :\n",
    "    return champ_data[str.lower(champ_name)]['tags'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:\n",
      "(74239, 51)\n",
      "\n",
      "dataframe sample:\n",
      "   total_gold_earned_0  total_gold_spent_0  total_baron_kills_0  \\\n",
      "0               102871              112435                    3   \n",
      "\n",
      "   total_dragon_kills_0  total_inhibitor_kils_0  total_kills_0  \\\n",
      "0                     3                       4             50   \n",
      "\n",
      "   total_deaths_0  total_damage_dealt_to_champions_0  \\\n",
      "0              67                             251493   \n",
      "\n",
      "   total_damage_dealt_to_objectives_0  total_damage_taken_0  ...  \\\n",
      "0                              114384                277343  ...   \n",
      "\n",
      "   team_comp_1_champ_5  gameLengthMin  dmg_to_champs_winner  \\\n",
      "0                 Mage              0                     0   \n",
      "\n",
      "   dmg_to_obj_winner vision_winner cs_winner champ_experience_winner  \\\n",
      "0                  0             0         1                       1   \n",
      "\n",
      "  wards_placed_winner gold_spender_winner final_match_winner  \n",
      "0                   1                   0                  1  \n",
      "\n",
      "[1 rows x 51 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../ml_data/full_ml_data.csv')\n",
    "columns = list(df.columns)\n",
    "champ_name_columns = [c for c in columns if c.startswith('team_comp') or c.startswith('dmg_carry') or c.startswith('obj_carry')]\n",
    "\n",
    "\n",
    "for c in champ_name_columns :\n",
    "    df[c] = df[c].apply(lambda x : champ_name_replacer(x))\n",
    "\n",
    "print(f\"dataframe shape:\\n{df.shape}\\n\")\n",
    "print(f\"dataframe sample:\\n{df.head(1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### MUST RETRIEVE ALL POSSIBLE CHAMP TAGS BEFORE BEING ABLE TO ONE HOT ENCODE. \n",
    "# ONE POSSIBLE SOLUTION IS TO ADD DUMMY DATA FOR WHICH IT WOULD HELP GENERATE THE ONE HOT ENCODE VALUE FOR EACH CHAMPION TAG FOR EACH CATEGORICAL FEATURE IN THE DATASET (6 CHAMP TAGS -> 6 EXTRA DUMMY ROWS, 1 FOR EACH CHAMP TAG)\n",
    "def fill_missing_champ_tags_with_dummy(df): \n",
    "    unique_champ_tags = df[champ_name_columns].stack().unique()\n",
    "    dummy_dict = {}\n",
    "    for k in champ_name_columns :\n",
    "        dummy_dict[k] = unique_champ_tags.copy()\n",
    "    dummy_df = pd.DataFrame(dummy_dict)\n",
    "    dummy_df = dummy_df.replace(np.nan,0)\n",
    "    extra_rows = dummy_df.shape[0]\n",
    "    print('Number of extra dummy rows = ',extra_rows)\n",
    "    df = add(df,dummy_df)\n",
    "    return (df,extra_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data and labels : (49740, 50) (49740,)\n",
      "Shape of test data and labels : (24499, 50) (24499,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = df.drop(\"final_match_winner\",axis=1)\n",
    "labels = df[\"final_match_winner\"].copy()\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(data,labels,test_size=0.33,random_state=42)\n",
    "\n",
    "print('Shape of training data and labels :',X_train.shape,y_train.shape)\n",
    "print('Shape of test data and labels :',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      " Empty DataFrame\n",
      "Columns: [total_gold_earned_0, total_gold_spent_0, total_baron_kills_0, total_dragon_kills_0, total_inhibitor_kils_0, total_kills_0, total_deaths_0, total_damage_dealt_to_champions_0, total_damage_dealt_to_objectives_0, total_damage_taken_0, average_vision_score_0, total_wards_placed_0, average_creep_score_0, average_champion_experience_0, dmg_carry_0, obj_carry_0, team_comp_0_champ_1, team_comp_0_champ_2, team_comp_0_champ_3, team_comp_0_champ_4, team_comp_0_champ_5, total_gold_earned_1, total_gold_spent_1, total_baron_kills_1, total_dragon_kills_1, total_inhibitor_kils_1, total_kills_1, total_deaths_1, total_damage_dealt_to_champions_1, total_damage_dealt_to_objectives_1, total_damage_taken_1, average_vision_score_1, total_wards_placed_1, average_creep_score_1, average_champion_experience_1, dmg_carry_1, obj_carry_1, team_comp_1_champ_1, team_comp_1_champ_2, team_comp_1_champ_3, team_comp_1_champ_4, team_comp_1_champ_5, gameLengthMin, dmg_to_champs_winner, dmg_to_obj_winner, vision_winner, cs_winner, champ_experience_winner, wards_placed_winner, gold_spender_winner]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 50 columns]\n",
      "Missing value row shape: (0, 50)\n"
     ]
    }
   ],
   "source": [
    "missing_value_row =  data[data.isnull().any(axis=1)].head()\n",
    "print(f'Rows with missing values:\\n {missing_value_row}')\n",
    "print(f'Missing value row shape: {missing_value_row.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (49746, 50)\n",
      "Columns of training data : Index(['total_gold_earned_0', 'total_gold_spent_0', 'total_baron_kills_0',\n",
      "       'total_dragon_kills_0', 'total_inhibitor_kils_0', 'total_kills_0',\n",
      "       'total_deaths_0', 'total_damage_dealt_to_champions_0',\n",
      "       'total_damage_dealt_to_objectives_0', 'total_damage_taken_0',\n",
      "       'average_vision_score_0', 'total_wards_placed_0',\n",
      "       'average_creep_score_0', 'average_champion_experience_0', 'dmg_carry_0',\n",
      "       'obj_carry_0', 'team_comp_0_champ_1', 'team_comp_0_champ_2',\n",
      "       'team_comp_0_champ_3', 'team_comp_0_champ_4', 'team_comp_0_champ_5',\n",
      "       'total_gold_earned_1', 'total_gold_spent_1', 'total_baron_kills_1',\n",
      "       'total_dragon_kills_1', 'total_inhibitor_kils_1', 'total_kills_1',\n",
      "       'total_deaths_1', 'total_damage_dealt_to_champions_1',\n",
      "       'total_damage_dealt_to_objectives_1', 'total_damage_taken_1',\n",
      "       'average_vision_score_1', 'total_wards_placed_1',\n",
      "       'average_creep_score_1', 'average_champion_experience_1', 'dmg_carry_1',\n",
      "       'obj_carry_1', 'team_comp_1_champ_1', 'team_comp_1_champ_2',\n",
      "       'team_comp_1_champ_3', 'team_comp_1_champ_4', 'team_comp_1_champ_5',\n",
      "       'gameLengthMin', 'dmg_to_champs_winner', 'dmg_to_obj_winner',\n",
      "       'vision_winner', 'cs_winner', 'champ_experience_winner',\n",
      "       'wards_placed_winner', 'gold_spender_winner'],\n",
      "      dtype='object')\n",
      "One hot encoded Training data shape (without dummy) : (49740, 120)\n"
     ]
    }
   ],
   "source": [
    "X_train,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_train)\n",
    "print('Training data shape (with dummy) :',X_train.shape)\n",
    "print('Columns of training data :',X_train.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_train.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "size = len(X_train_prepared)\n",
    "X_train_prepared = X_train_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Training data shape (without dummy) :',X_train_prepared.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data\n",
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "\n",
    "# Decision Trees\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forests\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\issam\\documents\\csi4900\\csi4900-ML\\src\\ml_analysis_by_performace.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/issam/documents/csi4900/csi4900-ML/src/ml_analysis_by_performace.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m grid_search_nb \u001b[39m=\u001b[39m GridSearchCV(nb_model,nb_params,scoring\u001b[39m=\u001b[39mscoring,cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,refit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbal_accuracy\u001b[39m\u001b[39m'\u001b[39m ,return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/issam/documents/csi4900/csi4900-ML/src/ml_analysis_by_performace.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# fit the training data (0.5)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/issam/documents/csi4900/csi4900-ML/src/ml_analysis_by_performace.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m grid_search_svc\u001b[39m.\u001b[39;49mfit(X_train_prepared,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/issam/documents/csi4900/csi4900-ML/src/ml_analysis_by_performace.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m grid_search_dt\u001b[39m.\u001b[39mfit(X_train_prepared,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/issam/documents/csi4900/csi4900-ML/src/ml_analysis_by_performace.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m grid_search_rf\u001b[39m.\u001b[39mfit(X_train_prepared,y_train)\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 251\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    252\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\issam\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    319\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    321\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    323\u001b[0m (\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 333\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    334\u001b[0m     X,\n\u001b[0;32m    335\u001b[0m     y,\n\u001b[0;32m    336\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    337\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    338\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[0;32m    339\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    340\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    341\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    342\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    343\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    344\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    345\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    346\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    347\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    348\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    349\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    350\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    351\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use sklearn GridSearchCV to train selected model with hyperparameter tuning\n",
    "# parameters for SVC:\n",
    "    # C -> e.g., 10, 100\n",
    "    # gamma ->  e.g., 0.001, 0.0001\n",
    "    # kernel -> 'rbf' or 'linear' \n",
    "\n",
    "svm_params = [\n",
    "    {'C':[10,100],'gamma':[0.001,0.0001],'kernel':['rbf','linear']}\n",
    "]\n",
    "\n",
    "# parameters for DecisionTreeClassifier: \n",
    "    # max_depth ->  e.g., 3, 4\n",
    "    # min_samples_split -> 5, 10\n",
    "    # min_samples_leaf -> 10, 20\n",
    "dt_params = [\n",
    "    {'max_depth':[3,4],'min_samples_split':[5,10],'min_samples_leaf':[10,20]}\n",
    "]\n",
    "\n",
    "# parameters for RandomForestClassifier: \n",
    "    # n_estimators -> 100, 200\n",
    "    # max_depth -> 3, 5\n",
    "    # bootstrap -> True, False\n",
    "rf_params = [\n",
    "    {'n_estimators':[100,200],'max_depth':[3,5],'bootstrap':[True,False]}\n",
    "]\n",
    "\n",
    "nb_params = [{}]\n",
    "# initialize gridsearch with the required parameters, including the following scoring methods and refit='bal_accuracy' (2)\n",
    "scoring = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "grid_search_svc = GridSearchCV(svm_model,svm_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_dt = GridSearchCV(dt_model,dt_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_rf = GridSearchCV(rf_model,rf_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_nb = GridSearchCV(nb_model,nb_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "\n",
    "# fit the training data (0.5)\n",
    "grid_search_svc.fit(X_train_prepared,y_train)\n",
    "grid_search_dt.fit(X_train_prepared,y_train)\n",
    "grid_search_rf.fit(X_train_prepared,y_train)\n",
    "grid_search_nb.fit(X_train_prepared,y_train)\n",
    "\n",
    "# print the best parameters (0.5)\n",
    "print(f'SVC best params:\\n{grid_search_svc.best_params_}')\n",
    "print(f'Decision Tree best params:\\n{grid_search_dt.best_params_}')\n",
    "print(f'Random Forest best params:\\n{grid_search_rf.best_params_}')\n",
    "print(f'Naive Bayes best params:\\n{grid_search_nb.best_params_}')\n",
    "\n",
    "# print the best estimator (0.5)\n",
    "print(f'SVC best estimator:\\n{grid_search_svc.best_estimator_}')\n",
    "print(f'Decision Tree best estimator:\\n{grid_search_dt.best_estimator_}')\n",
    "print(f'Random Forest best estimator:\\n{grid_search_rf.best_estimator_}')\n",
    "print(f'Naive Bayes best estimator:\\n{grid_search_nb.best_estimator_}')\n",
    "\n",
    "# print the best score from trained GridSearchCV model (0.5)\n",
    "print(f'SVC best score:\\n{grid_search_svc.best_score_}')\n",
    "print(f'Decision Tree best score:\\n{grid_search_dt.best_score_}')\n",
    "print(f'Random Forest best score:\\n{grid_search_rf.best_score_}')\n",
    "print(f'Naive Bayes best score:\\n{grid_search_nb.best_score_}')\n",
    "\n",
    "# Save session to \"notebook_env.db\"\n",
    "dill.dump_session(\"notebook_env.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jupyter notebook state\n",
    "dill.load_session(\"notebook_env.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (24505, 50)\n",
      "Columns of training data : Index(['total_gold_earned_0', 'total_gold_spent_0', 'total_baron_kills_0',\n",
      "       'total_dragon_kills_0', 'total_inhibitor_kils_0', 'total_kills_0',\n",
      "       'total_deaths_0', 'total_damage_dealt_to_champions_0',\n",
      "       'total_damage_dealt_to_objectives_0', 'total_damage_taken_0',\n",
      "       'average_vision_score_0', 'total_wards_placed_0',\n",
      "       'average_creep_score_0', 'average_champion_experience_0', 'dmg_carry_0',\n",
      "       'obj_carry_0', 'team_comp_0_champ_1', 'team_comp_0_champ_2',\n",
      "       'team_comp_0_champ_3', 'team_comp_0_champ_4', 'team_comp_0_champ_5',\n",
      "       'total_gold_earned_1', 'total_gold_spent_1', 'total_baron_kills_1',\n",
      "       'total_dragon_kills_1', 'total_inhibitor_kils_1', 'total_kills_1',\n",
      "       'total_deaths_1', 'total_damage_dealt_to_champions_1',\n",
      "       'total_damage_dealt_to_objectives_1', 'total_damage_taken_1',\n",
      "       'average_vision_score_1', 'total_wards_placed_1',\n",
      "       'average_creep_score_1', 'average_champion_experience_1', 'dmg_carry_1',\n",
      "       'obj_carry_1', 'team_comp_1_champ_1', 'team_comp_1_champ_2',\n",
      "       'team_comp_1_champ_3', 'team_comp_1_champ_4', 'team_comp_1_champ_5',\n",
      "       'gameLengthMin', 'dmg_to_champs_winner', 'dmg_to_obj_winner',\n",
      "       'vision_winner', 'cs_winner', 'champ_experience_winner',\n",
      "       'wards_placed_winner', 'gold_spender_winner'],\n",
      "      dtype='object')\n",
      "One hot encoded Training data shape (without dummy) : (24499, 120)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X_test dataset based on previous method for X_train\n",
    "X_test,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_test)\n",
    "print('Training data shape (with dummy) :',X_test.shape)\n",
    "print('Columns of training data :',X_test.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_test.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
    "size = len(X_test_prepared)\n",
    "X_test_prepared = X_test_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Testing data shape (without dummy) :',X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models with test data\n",
    "\n",
    "# Using the following existing variables:\n",
    "# X_test_prepared: test data\n",
    "# y_test: test labels\n",
    "# Models:\n",
    "# grid_search_svc\n",
    "# grid_search_dt\n",
    "# grid_search_rf\n",
    "# grid_search_nb\n",
    "\n",
    "# Predict using models' best estimators\n",
    "prediction_svc = grid_search_svc.best_estimator_.predict(X_test_prepared)\n",
    "prediction_dt = grid_search_dt.best_estimator_.predict(X_test_prepared)\n",
    "prediction_rf = grid_search_rf.best_estimator_.predict(X_test_prepared)\n",
    "prediction_nb = grid_search_nb.best_estimator_.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: SVC:\n",
      "[[6953 5619]\n",
      " [6786 5141]]\n",
      "\n",
      "Confusion matrix: DT:\n",
      "[[5559 7013]\n",
      " [6512 5415]]\n",
      "\n",
      "Confusion matrix: RF:\n",
      "[[5534 7038]\n",
      " [7285 4642]]\n",
      "\n",
      "Confusion matrix: NB:\n",
      "[[6637 5935]\n",
      " [6517 5410]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and print classification reports for all models\n",
    "\n",
    "# SVC\n",
    "conf_matrix_svc = confusion_matrix(y_test, prediction_svc)\n",
    "class_report_svc = classification_report(y_test, prediction_svc, output_dict=True)\n",
    "print(f'Confusion matrix: SVC:\\n{conf_matrix_svc}\\n')\n",
    "\n",
    "# Decision Tree\n",
    "conf_matrix_dt = confusion_matrix(y_test, prediction_dt)\n",
    "class_report_dt = classification_report(y_test, prediction_dt, output_dict=True)\n",
    "print(f'Confusion matrix: DT:\\n{conf_matrix_dt}\\n')\n",
    "\n",
    "# Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, prediction_rf)\n",
    "class_report_rf = classification_report(y_test, prediction_rf, output_dict=True)\n",
    "print(f'Confusion matrix: RF:\\n{conf_matrix_rf}\\n')\n",
    "\n",
    "# Naive Bayes\n",
    "conf_matrix_nb = confusion_matrix(y_test, prediction_nb)\n",
    "class_report_nb = classification_report(y_test, prediction_nb, output_dict=True)\n",
    "print(f'Confusion matrix: NB:\\n{conf_matrix_nb}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "accuracy       0.493653  0.493653  0.493653      0.493653\n",
      "macro avg      0.491933  0.492047  0.490868  24499.000000\n",
      "weighted avg   0.492305  0.493653  0.491859  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.447937  0.447937  0.447937      0.447937\n",
      "macro avg      0.448117  0.448092  0.447918  24499.000000\n",
      "weighted avg   0.448444  0.447937  0.448003  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.415364  0.415364  0.415364      0.415364\n",
      "macro avg      0.414567  0.414693  0.414588  24499.000000\n",
      "weighted avg   0.415018  0.415364  0.415149  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.491734  0.491734  0.491734      0.491734\n",
      "macro avg      0.490712  0.490756  0.490456  24499.000000\n",
      "weighted avg   0.491076  0.491734  0.491128  24499.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print our classification reports\n",
    "\n",
    "# SVC\n",
    "df_svc = pd.DataFrame(class_report_svc).transpose().drop(['0', '1'])\n",
    "print(f\"{df_svc}\\n\")\n",
    "\n",
    "# DT\n",
    "df_dt = pd.DataFrame(class_report_dt).transpose().drop(['0', '1'])\n",
    "print(f\"{df_dt}\\n\")\n",
    "\n",
    "# RF\n",
    "df_rf = pd.DataFrame(class_report_rf).transpose().drop(['0', '1'])\n",
    "print(f\"{df_rf}\\n\")\n",
    "\n",
    "# NB\n",
    "df_nb = pd.DataFrame(class_report_nb).transpose().drop(['0', '1'])\n",
    "print(f\"{df_nb}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save session to \"notebook_env.db\"\n",
    "dill.dump_session(\"notebook_env.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e80926609d05e9d93fc8f5a4ca830eb95187a74de0c9b551d07cafde795a7924"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
