{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas, numpy, matplotlib and seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# RiotWatcher\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import sys\n",
    "import dill\n",
    "import ipython_genutils\n",
    "\n",
    "# Custom scripts\n",
    "from extract_players_performance import extract_players_performance\n",
    "from remove_perks import remove_perks\n",
    "from cleaner import replace_champ_names_with_tags\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_data = {}\n",
    "with open('../champion_data/champion.json','r',encoding='utf-8') as f :\n",
    "    champions = json.load(f)\n",
    "    for champion in champions['data'] :\n",
    "        champ_data[str.lower(champion)] = champions['data'][champion]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def add(old,new_df) :\n",
    "    appended_df = pd.concat([old,new_df],ignore_index=True)\n",
    "    return appended_df\n",
    "\n",
    "def champ_name_replacer(champ_name) :\n",
    "    return champ_data[str.lower(champ_name)]['tags'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:\n",
      "(74239, 51)\n",
      "\n",
      "dataframe sample:\n",
      "   total_gold_earned_0  total_gold_spent_0  total_baron_kills_0  \\\n",
      "0               102871              112435                    3   \n",
      "\n",
      "   total_dragon_kills_0  total_inhibitor_kils_0  total_kills_0  \\\n",
      "0                     3                       4             50   \n",
      "\n",
      "   total_deaths_0  total_damage_dealt_to_champions_0  \\\n",
      "0              67                             251493   \n",
      "\n",
      "   total_damage_dealt_to_objectives_0  total_damage_taken_0  ...  \\\n",
      "0                              114384                277343  ...   \n",
      "\n",
      "   team_comp_1_champ_5  gameLengthMin  dmg_to_champs_winner  \\\n",
      "0                 Mage              0                     0   \n",
      "\n",
      "   dmg_to_obj_winner vision_winner cs_winner champ_experience_winner  \\\n",
      "0                  0             0         1                       1   \n",
      "\n",
      "  wards_placed_winner gold_spender_winner final_match_winner  \n",
      "0                   1                   0                  1  \n",
      "\n",
      "[1 rows x 51 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../ml_data/full_ml_data.csv')\n",
    "columns = list(df.columns)\n",
    "champ_name_columns = [c for c in columns if c.startswith('team_comp') or c.startswith('dmg_carry') or c.startswith('obj_carry')]\n",
    "\n",
    "\n",
    "for c in champ_name_columns :\n",
    "    df[c] = df[c].apply(lambda x : champ_name_replacer(x))\n",
    "\n",
    "print(f\"dataframe shape:\\n{df.shape}\\n\")\n",
    "print(f\"dataframe sample:\\n{df.head(1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### MUST RETRIEVE ALL POSSIBLE CHAMP TAGS BEFORE BEING ABLE TO ONE HOT ENCODE. \n",
    "# ONE POSSIBLE SOLUTION IS TO ADD DUMMY DATA FOR WHICH IT WOULD HELP GENERATE THE ONE HOT ENCODE VALUE FOR EACH CHAMPION TAG FOR EACH CATEGORICAL FEATURE IN THE DATASET (6 CHAMP TAGS -> 6 EXTRA DUMMY ROWS, 1 FOR EACH CHAMP TAG)\n",
    "def fill_missing_champ_tags_with_dummy(df): \n",
    "    unique_champ_tags = df[champ_name_columns].stack().unique()\n",
    "    dummy_dict = {}\n",
    "    for k in champ_name_columns :\n",
    "        dummy_dict[k] = unique_champ_tags.copy()\n",
    "    dummy_df = pd.DataFrame(dummy_dict)\n",
    "    dummy_df = dummy_df.replace(np.nan,0)\n",
    "    extra_rows = dummy_df.shape[0]\n",
    "    print('Number of extra dummy rows = ',extra_rows)\n",
    "    df = add(df,dummy_df)\n",
    "    return (df,extra_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74239, 51)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data and labels : (49740, 50) (49740,)\n",
      "Shape of test data and labels : (24499, 50) (24499,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = df.drop(\"final_match_winner\",axis=1)\n",
    "labels = df[\"final_match_winner\"].copy()\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(data,labels,test_size=0.33,random_state=42)\n",
    "\n",
    "print('Shape of training data and labels :',X_train.shape,y_train.shape)\n",
    "print('Shape of test data and labels :',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      " Empty DataFrame\n",
      "Columns: [total_gold_earned_0, total_gold_spent_0, total_baron_kills_0, total_dragon_kills_0, total_inhibitor_kils_0, total_kills_0, total_deaths_0, total_damage_dealt_to_champions_0, total_damage_dealt_to_objectives_0, total_damage_taken_0, average_vision_score_0, total_wards_placed_0, average_creep_score_0, average_champion_experience_0, dmg_carry_0, obj_carry_0, team_comp_0_champ_1, team_comp_0_champ_2, team_comp_0_champ_3, team_comp_0_champ_4, team_comp_0_champ_5, total_gold_earned_1, total_gold_spent_1, total_baron_kills_1, total_dragon_kills_1, total_inhibitor_kils_1, total_kills_1, total_deaths_1, total_damage_dealt_to_champions_1, total_damage_dealt_to_objectives_1, total_damage_taken_1, average_vision_score_1, total_wards_placed_1, average_creep_score_1, average_champion_experience_1, dmg_carry_1, obj_carry_1, team_comp_1_champ_1, team_comp_1_champ_2, team_comp_1_champ_3, team_comp_1_champ_4, team_comp_1_champ_5, gameLengthMin, dmg_to_champs_winner, dmg_to_obj_winner, vision_winner, cs_winner, champ_experience_winner, wards_placed_winner, gold_spender_winner]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 50 columns]\n",
      "Missing value row shape: (0, 50)\n"
     ]
    }
   ],
   "source": [
    "missing_value_row =  data[data.isnull().any(axis=1)].head()\n",
    "print(f'Rows with missing values:\\n {missing_value_row}')\n",
    "print(f'Missing value row shape: {missing_value_row.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (49746, 50)\n",
      "Columns of training data : Index(['total_gold_earned_0', 'total_gold_spent_0', 'total_baron_kills_0',\n",
      "       'total_dragon_kills_0', 'total_inhibitor_kils_0', 'total_kills_0',\n",
      "       'total_deaths_0', 'total_damage_dealt_to_champions_0',\n",
      "       'total_damage_dealt_to_objectives_0', 'total_damage_taken_0',\n",
      "       'average_vision_score_0', 'total_wards_placed_0',\n",
      "       'average_creep_score_0', 'average_champion_experience_0', 'dmg_carry_0',\n",
      "       'obj_carry_0', 'team_comp_0_champ_1', 'team_comp_0_champ_2',\n",
      "       'team_comp_0_champ_3', 'team_comp_0_champ_4', 'team_comp_0_champ_5',\n",
      "       'total_gold_earned_1', 'total_gold_spent_1', 'total_baron_kills_1',\n",
      "       'total_dragon_kills_1', 'total_inhibitor_kils_1', 'total_kills_1',\n",
      "       'total_deaths_1', 'total_damage_dealt_to_champions_1',\n",
      "       'total_damage_dealt_to_objectives_1', 'total_damage_taken_1',\n",
      "       'average_vision_score_1', 'total_wards_placed_1',\n",
      "       'average_creep_score_1', 'average_champion_experience_1', 'dmg_carry_1',\n",
      "       'obj_carry_1', 'team_comp_1_champ_1', 'team_comp_1_champ_2',\n",
      "       'team_comp_1_champ_3', 'team_comp_1_champ_4', 'team_comp_1_champ_5',\n",
      "       'gameLengthMin', 'dmg_to_champs_winner', 'dmg_to_obj_winner',\n",
      "       'vision_winner', 'cs_winner', 'champ_experience_winner',\n",
      "       'wards_placed_winner', 'gold_spender_winner'],\n",
      "      dtype='object')\n",
      "One hot encoded Training data shape (without dummy) : (49740, 120)\n"
     ]
    }
   ],
   "source": [
    "X_train,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_train)\n",
    "print('Training data shape (with dummy) :',X_train.shape)\n",
    "print('Columns of training data :',X_train.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_train.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "size = len(X_train_prepared)\n",
    "X_train_prepared = X_train_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Training data shape (without dummy) :',X_train_prepared.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data\n",
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "\n",
    "# Decision Trees\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forests\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC best params:\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Decision Tree best params:\n",
      "{'max_depth': 4, 'min_samples_leaf': 20, 'min_samples_split': 5}\n",
      "Random Forest best params:\n",
      "{'bootstrap': False, 'max_depth': 5, 'n_estimators': 100}\n",
      "Naive Bayes best params:\n",
      "{}\n",
      "SVC best estimator:\n",
      "SVC(C=100, gamma=0.001)\n",
      "Decision Tree best estimator:\n",
      "DecisionTreeClassifier(max_depth=4, min_samples_leaf=20, min_samples_split=5)\n",
      "Random Forest best estimator:\n",
      "RandomForestClassifier(bootstrap=False, max_depth=5)\n",
      "Naive Bayes best estimator:\n",
      "GaussianNB()\n",
      "SVC best score:\n",
      "0.9895644071744701\n",
      "Decision Tree best score:\n",
      "0.9828303342650827\n",
      "Random Forest best score:\n",
      "0.9772318794161038\n",
      "Naive Bayes best score:\n",
      "0.9541117808059631\n"
     ]
    }
   ],
   "source": [
    "# use sklearn GridSearchCV to train selected model with hyperparameter tuning\n",
    "# parameters for SVC:\n",
    "    # C -> e.g., 10, 100\n",
    "    # gamma ->  e.g., 0.001, 0.0001\n",
    "    # kernel -> 'rbf' or 'linear' \n",
    "\n",
    "svm_params = [\n",
    "    {'C':[10,100],'gamma':[0.001,0.0001],'kernel':['rbf','linear']}\n",
    "]\n",
    "\n",
    "# parameters for DecisionTreeClassifier: \n",
    "    # max_depth ->  e.g., 3, 4\n",
    "    # min_samples_split -> 5, 10\n",
    "    # min_samples_leaf -> 10, 20\n",
    "dt_params = [\n",
    "    {'max_depth':[3,4],'min_samples_split':[5,10],'min_samples_leaf':[10,20]}\n",
    "]\n",
    "\n",
    "# parameters for RandomForestClassifier: \n",
    "    # n_estimators -> 100, 200\n",
    "    # max_depth -> 3, 5\n",
    "    # bootstrap -> True, False\n",
    "rf_params = [\n",
    "    {'n_estimators':[100,200],'max_depth':[3,5],'bootstrap':[True,False]}\n",
    "]\n",
    "\n",
    "nb_params = [{}]\n",
    "# initialize gridsearch with the required parameters, including the following scoring methods and refit='bal_accuracy' (2)\n",
    "scoring = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "grid_search_svc = GridSearchCV(svm_model,svm_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_dt = GridSearchCV(dt_model,dt_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_rf = GridSearchCV(rf_model,rf_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "grid_search_nb = GridSearchCV(nb_model,nb_params,scoring=scoring,cv=5,refit='bal_accuracy' ,return_train_score=True)\n",
    "\n",
    "# fit the training data (0.5)\n",
    "grid_search_svc.fit(X_train_prepared,y_train)\n",
    "grid_search_dt.fit(X_train_prepared,y_train)\n",
    "grid_search_rf.fit(X_train_prepared,y_train)\n",
    "grid_search_nb.fit(X_train_prepared,y_train)\n",
    "\n",
    "# print the best parameters (0.5)\n",
    "print(f'SVC best params:\\n{grid_search_svc.best_params_}')\n",
    "print(f'Decision Tree best params:\\n{grid_search_dt.best_params_}')\n",
    "print(f'Random Forest best params:\\n{grid_search_rf.best_params_}')\n",
    "print(f'Naive Bayes best params:\\n{grid_search_nb.best_params_}')\n",
    "\n",
    "# print the best estimator (0.5)\n",
    "print(f'SVC best estimator:\\n{grid_search_svc.best_estimator_}')\n",
    "print(f'Decision Tree best estimator:\\n{grid_search_dt.best_estimator_}')\n",
    "print(f'Random Forest best estimator:\\n{grid_search_rf.best_estimator_}')\n",
    "print(f'Naive Bayes best estimator:\\n{grid_search_nb.best_estimator_}')\n",
    "\n",
    "# print the best score from trained GridSearchCV model (0.5)\n",
    "print(f'SVC best score:\\n{grid_search_svc.best_score_}')\n",
    "print(f'Decision Tree best score:\\n{grid_search_dt.best_score_}')\n",
    "print(f'Random Forest best score:\\n{grid_search_rf.best_score_}')\n",
    "print(f'Naive Bayes best score:\\n{grid_search_nb.best_score_}')\n",
    "\n",
    "# Save session to \"notebook_env.db\"\n",
    "dill.dump_session(\"notebook_env.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jupyter notebook state\n",
    "dill.load_session(\"notebook_env.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extra dummy rows =  6\n",
      "Training data shape (with dummy) : (24505, 50)\n",
      "Columns of training data : Index(['total_gold_earned_0', 'total_gold_spent_0', 'total_baron_kills_0',\n",
      "       'total_dragon_kills_0', 'total_inhibitor_kils_0', 'total_kills_0',\n",
      "       'total_deaths_0', 'total_damage_dealt_to_champions_0',\n",
      "       'total_damage_dealt_to_objectives_0', 'total_damage_taken_0',\n",
      "       'average_vision_score_0', 'total_wards_placed_0',\n",
      "       'average_creep_score_0', 'average_champion_experience_0', 'dmg_carry_0',\n",
      "       'obj_carry_0', 'team_comp_0_champ_1', 'team_comp_0_champ_2',\n",
      "       'team_comp_0_champ_3', 'team_comp_0_champ_4', 'team_comp_0_champ_5',\n",
      "       'total_gold_earned_1', 'total_gold_spent_1', 'total_baron_kills_1',\n",
      "       'total_dragon_kills_1', 'total_inhibitor_kils_1', 'total_kills_1',\n",
      "       'total_deaths_1', 'total_damage_dealt_to_champions_1',\n",
      "       'total_damage_dealt_to_objectives_1', 'total_damage_taken_1',\n",
      "       'average_vision_score_1', 'total_wards_placed_1',\n",
      "       'average_creep_score_1', 'average_champion_experience_1', 'dmg_carry_1',\n",
      "       'obj_carry_1', 'team_comp_1_champ_1', 'team_comp_1_champ_2',\n",
      "       'team_comp_1_champ_3', 'team_comp_1_champ_4', 'team_comp_1_champ_5',\n",
      "       'gameLengthMin', 'dmg_to_champs_winner', 'dmg_to_obj_winner',\n",
      "       'vision_winner', 'cs_winner', 'champ_experience_winner',\n",
      "       'wards_placed_winner', 'gold_spender_winner'],\n",
      "      dtype='object')\n",
      "One hot encoded Training data shape (without dummy) : (24499, 120)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X_test dataset based on previous method for X_train\n",
    "X_test,dummy_rows_len = fill_missing_champ_tags_with_dummy(X_test)\n",
    "print('Training data shape (with dummy) :',X_test.shape)\n",
    "print('Columns of training data :',X_test.columns)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "full_column_set,cat_column_set = set(list(X_test.columns)),set(champ_name_columns)\n",
    "num_columns = list(full_column_set - cat_column_set)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num',num_pipeline,num_columns),\n",
    "        (\"cat\", OneHotEncoder(), champ_name_columns),\n",
    "    ],remainder='passthrough')\n",
    "\n",
    "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
    "size = len(X_test_prepared)\n",
    "X_test_prepared = X_test_prepared[:size-dummy_rows_len]\n",
    "print('One hot encoded Training data shape (without dummy) :',X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models with test data\n",
    "\n",
    "# Using the following existing variables:\n",
    "# X_test_prepared: test data\n",
    "# y_test: test labels\n",
    "# Models:\n",
    "# grid_search_svc\n",
    "# grid_search_dt\n",
    "# grid_search_rf\n",
    "# grid_search_nb\n",
    "\n",
    "# Predict using models' best estimators\n",
    "prediction_svc = grid_search_svc.best_estimator_.predict(X_test_prepared)\n",
    "prediction_dt = grid_search_dt.best_estimator_.predict(X_test_prepared)\n",
    "prediction_rf = grid_search_rf.best_estimator_.predict(X_test_prepared)\n",
    "prediction_nb = grid_search_nb.best_estimator_.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: SVC:\n",
      "[[6953 5619]\n",
      " [6786 5141]]\n",
      "\n",
      "Confusion matrix: DT:\n",
      "[[5559 7013]\n",
      " [6512 5415]]\n",
      "\n",
      "Confusion matrix: RF:\n",
      "[[5534 7038]\n",
      " [7285 4642]]\n",
      "\n",
      "Confusion matrix: NB:\n",
      "[[6637 5935]\n",
      " [6517 5410]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and print classification reports for all models\n",
    "\n",
    "# SVC\n",
    "conf_matrix_svc = confusion_matrix(y_test, prediction_svc)\n",
    "class_report_svc = classification_report(y_test, prediction_svc, output_dict=True)\n",
    "print(f'Confusion matrix: SVC:\\n{conf_matrix_svc}\\n')\n",
    "\n",
    "# Decision Tree\n",
    "conf_matrix_dt = confusion_matrix(y_test, prediction_dt)\n",
    "class_report_dt = classification_report(y_test, prediction_dt, output_dict=True)\n",
    "print(f'Confusion matrix: DT:\\n{conf_matrix_dt}\\n')\n",
    "\n",
    "# Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, prediction_rf)\n",
    "class_report_rf = classification_report(y_test, prediction_rf, output_dict=True)\n",
    "print(f'Confusion matrix: RF:\\n{conf_matrix_rf}\\n')\n",
    "\n",
    "# Naive Bayes\n",
    "conf_matrix_nb = confusion_matrix(y_test, prediction_nb)\n",
    "class_report_nb = classification_report(y_test, prediction_nb, output_dict=True)\n",
    "print(f'Confusion matrix: NB:\\n{conf_matrix_nb}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "accuracy       0.493653  0.493653  0.493653      0.493653\n",
      "macro avg      0.491933  0.492047  0.490868  24499.000000\n",
      "weighted avg   0.492305  0.493653  0.491859  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.447937  0.447937  0.447937      0.447937\n",
      "macro avg      0.448117  0.448092  0.447918  24499.000000\n",
      "weighted avg   0.448444  0.447937  0.448003  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.415364  0.415364  0.415364      0.415364\n",
      "macro avg      0.414567  0.414693  0.414588  24499.000000\n",
      "weighted avg   0.415018  0.415364  0.415149  24499.000000\n",
      "\n",
      "              precision    recall  f1-score       support\n",
      "accuracy       0.491734  0.491734  0.491734      0.491734\n",
      "macro avg      0.490712  0.490756  0.490456  24499.000000\n",
      "weighted avg   0.491076  0.491734  0.491128  24499.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print our classification reports\n",
    "\n",
    "# SVC\n",
    "df_svc = pd.DataFrame(class_report_svc).transpose().drop(['0', '1'])\n",
    "print(f\"{df_svc}\\n\")\n",
    "\n",
    "# DT\n",
    "df_dt = pd.DataFrame(class_report_dt).transpose().drop(['0', '1'])\n",
    "print(f\"{df_dt}\\n\")\n",
    "\n",
    "# RF\n",
    "df_rf = pd.DataFrame(class_report_rf).transpose().drop(['0', '1'])\n",
    "print(f\"{df_rf}\\n\")\n",
    "\n",
    "# NB\n",
    "df_nb = pd.DataFrame(class_report_nb).transpose().drop(['0', '1'])\n",
    "print(f\"{df_nb}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save session to \"notebook_env.db\"\n",
    "dill.dump_session(\"notebook_env.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('honours')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7b7b3ece1175e03f6d4ad1d6f449bb296e00ba8bb500d8c0af43823720e462e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
